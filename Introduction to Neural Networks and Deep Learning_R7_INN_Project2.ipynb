{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics\n",
    "# Create KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "X_train\n",
      "X_val\n",
      "y_test\n",
      "y_train\n",
      "y_val\n"
     ]
    }
   ],
   "source": [
    "# Read H5 file\n",
    "f = h5.File(\"SVHN_single_grey1.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = [n for n in f.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['X_test'].shape\n",
    "f['X_train'].shape\n",
    "f['X_val'].shape\n",
    "f['y_test'].shape\n",
    "f['y_train'].shape\n",
    "f['y_val'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetching and understand the train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = f['X_test']\n",
    "X_train = f['X_train']\n",
    "X_val = f['X_val']\n",
    "\n",
    "y_test = f['y_test']\n",
    "y_train = f['y_train']\n",
    "y_val = f['y_val']\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape\n",
    "X_val.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 20767 is 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c03a313198>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGmRJREFUeJztnVusXGd1x/9r7z23c/Hl+BbXdpqLIpUUFUNPI6pUiEJbpQgpIAEiDygPEUYVkYpEH6JUKqnUB6gKiJdSmSYiVJQQbiIqaUsUUUU8EDBp4gRMyaVO4vjEl/jYPre57tWHGUsn7rfWmbPPnD023/8nWZ6z13x7r/n2XrNnvv+stURVQQiJj2TcDhBCxgODn5BIYfATEikMfkIihcFPSKQw+AmJFAY/IZHC4CckUhj8hERKtpHBInIbgC8BSAH8s6p+1nt+NWloI502rEV+aSgFxhQfVmiHiWMTx9bt2rZeXuB4nh+2aeSTNfK5XwPrsnJ/2erYPNOIfy0r3vVhsJIvoq3NoQZKUYdFJAXwawB/CuAEgJ8BuENVf2mN2VrZrX8486GwUZ0L2vIxSe0xTtAVmdTBwPD21PZDGzV7f9WKbXv9jL3PpWXTJtVq2OD46L5BeXPsYexTknI/bGpuXFftjj2o17P359m8N+wCiHfODH6y8gNc6J0d6gLfyJm4BcALqvqSqrYBPATg9g3sjxBSIhsJ/n0AXl3194nBNkLIVcBGvvOHPlr8v8/nInIIwCEAqCdTGzgcIWSUbOTOfwLAgVV/7wdw8vInqephVZ1V1dlq0tjA4Qgho2Qjwf8zADeJyPUiUgXwUQCPjMYtQshmU/hjv6p2ReRuAP+JvtT3gKr+wh0kAqkZq9HeKmrHWJnN7THwxIPcUTgKSHNF1StN7ZHJ1KQ90FmBF0tBKLrKnjkrzkVUE2v1HQC6zvn0rg9vn1cKBa45T1mwWI96tyGdX1UfBfDoRvZBCBkP/IUfIZHC4CckUhj8hEQKg5+QSGHwExIpG1rtX//RUuQz4aw+WWmbw2RhKbjdTaRwbNpxxnlSiZVoUSABA4Arv+nUhD1uom6a8orhi3csR3LMq8UuETEyD5OWPffuNbDctA/mSX2GXOZeOwX2t6bNo+CwMMNLfbzzExIpDH5CIoXBT0ikMPgJiRQGPyGRUupqf15J0Pyt8Gp/ZcEuq5QZySWyuGKO0RXb5tbAs5KIAHNV3ytNpRV7ivO6bevO2OnPvZp9vLwaXrnPM3tF313t9/J6nGlM2+FV58qCvcpevWDPh3eXkgUn6afVckaOGHGuA08JsBLUiiROraMqH+/8hEQKg5+QSGHwExIpDH5CIoXBT0ikMPgJiZRSpb5eVbCwP3zI6qKtKTVqYVtl3qgHCCB1ZCM4HW/QdsZlYZtO2/X2ulttya49Y/u/tMf2oz3tyHbGsJ59KORO4yC3y5eTG1Mxprh63r7fTNTta6CW2eMyJxlLLJsn6TqJX56S5gpzTkcqVWOkIx2KVWuSUh8hZC0Y/IRECoOfkEhh8BMSKQx+QiKFwU9IpGxI6hOR4wAW0K9C1lXVWe/5eQ24eEPYVlmw34c6jbBONTHhSEMN+6Vl87a2JU27jpyVodfdFc5UBICWJ+fttv1fMOYJANozjsaWhrUeqdtZZVnV2Z9D3rP9X7kYnuPaGXtM1zlnUxVbSGs4GpuZEbriZPs5Up8n52nblg/FyS7UtnHNeS3WrAzTxeHv56PQ+f9YVc+OYD+EkBLhx35CImWjwa8AfigiPxeRQ6NwiBBSDhv92H+rqp4Ukd0AHhORX6nqE6ufMHhTOAQA2bbtGzwcIWRUbOjOr6onB/+fBvA9ALcEnnNYVWdVdTaddHrOE0JKpXDwi8ikiExfegzgzwA8NyrHCCGby0Y+9u8B8D3pFxnMAPyrqv6HO6KWQ24Mt95anrdbUGlqZNM5bbI0q9luWBlRAJK20wqrGj5ec5d9rJUd9vvryi7bj84+Wxqa2bFg2iarYblppm5nMu6ohc8JANRSW/Y617Zbir18MfwV7/Wq99XPlmDTjpPhljvnOg2Pq5xz7nuOZOchTrFWVJ3USet4TiagmfG3XILUp6ovAXhb0fGEkPFCqY+QSGHwExIpDH5CIoXBT0ikMPgJiZRSC3jWKx285ZpTQdtLtRlz3GJra3B72nKKOq7YtqTtSEpNWz7s1cP7bG2xj9Xeast57e12tcWpbbY0d/22c6ZtezXco3B/fd4cs6dywbRNJLbkeK43Zdom0/3B7cstO8txYWmLaWuft89L5shbiVGQNXH8SJzehdKzz5k6WXheP0dTIvR6SlqFSdfR3493fkIihcFPSKQw+AmJFAY/IZHC4CckUkpd7W+kHdy8ZS5oW+o6q8C1cI283GnhpM6KrYfkTusnZ/HVwmuFlVftY3U69qlZcJKP6kYiTuo4X0/sRJYtadO05c69Y6YaThaqVexEIaeMo4t3XpJO2CjeSnpRnLZhhcidFl9dYx7X4QPv/IRECoOfkEhh8BMSKQx+QiKFwU9IpDD4CYmUUqW+BIqpNJwo4tWKQ2K0oHJUjaRrG9OmLaEkLbutlTnGaVvlNXhSR43sGAkpAHB22a6dZzFTtVuK7czsmoBLYtfHW3Jq5630wtJt05EwpW1PSGp3UUPads51y5D6OvZ5lpZzLTrym3i1/xybdg1fOk7rOKulmOPf5fDOT0ikMPgJiRQGPyGRwuAnJFIY/IRECoOfkEhZU+oTkQcAvB/AaVV962DbDIBvArgOwHEAH1FVu0jcAAXQ0vAhO55c1gtLQE4yGrIVW/7JFm0JJV20a9blE2H5KltxagKGS+r1xy077bou2vs8n9sNT615bGT2ZDVS23Zt7Q3TtpzbmZgXu2EZ0MtWTBypL3HkvMyVbsOSmDTt1+xKdk42oDbtawct26bt8PWoBTIPdcRZfV8FcNtl2+4B8Liq3gTg8cHfhJCriDWDX1WfAHB5udjbATw4ePwggA+M2C9CyCZT9Dv/HlWdA4DB/7tH5xIhpAw2fcFPRA6JyBERObI07/xGkxBSKkWD/5SI7AWAwf+nrSeq6mFVnVXV2cnt9gIRIaRcigb/IwDuHDy+E8D3R+MOIaQshpH6vgHg3QB2isgJAJ8B8FkAD4vIXQBeAfDhYQ7WzjOcbG4L2i627Qwx6RpSn/MtIlu2s7bS+XBxSQCQBduWtMPZdLWttu9eIdFsxbYt77VPTXu7/Z690A3bTjqFM3fVF03b/qqt4M6k9lxdPxGWCF/dtt0cc3zGLkzaOW1Ln3mlQLHW1LnvOa21vAKZUnM+2VZt/y3v1ZMcjQKecmH4+/mawa+qdxim9w59FELIFQd/4UdIpDD4CYkUBj8hkcLgJyRSGPyEREqpBTxzCBaMbK9e7kkvxvZi7fggTacwYsu2SSUs16QrtoxWWXT6CYqdydidtF9cXnWyAbPwKV1q2jLUfLth2ppGFiYATIudsjhl9PjbWrV7/0nNlmd7NVsq63lSX2LYPDnPw+nliMw+n+rYIGEfxfOxY9is1xt66tDPJIT8RsHgJyRSGPyERAqDn5BIYfATEikMfkIipfRefVaxyGpqyzxaCRcy7NVt+aTXcCS2hpNB6PQ6U0NuUidDzMs4y231CuK0DPQKXVoZkF7vv4W2nU13tmP3+Ks4Ti73wnPcVS9jrph2q4685Z2bQnhSmiHZrYVYhTq9a9EaM3z9Tt75CYkVBj8hkcLgJyRSGPyERAqDn5BIKXW1H+iv+IfIEqc1URIe4y4ce6uy3gqwt2Jr2TbhLdRd7XdKuyVNY7W/aZ/qCy1ntb81ZdrqjiNNQ8roeglcYi9Vq5MX49qy8Hyoc57Fa3nlJfY4/l+J8M5PSKQw+AmJFAY/IZHC4CckUhj8hEQKg5+QSBmmXdcDAN4P4LSqvnWw7T4AHwdwZvC0e1X10WEOmBuF98STSYy3qNyTeArW97PaIAGAdI3pclRKN+nElRUdk6eKWupby56spVax+n7TFbsen5X040m6iZHABQBOKUH0nJqGvUr44smuoNuedY0UvYSHZZgp+CqA2wLbv6iqBwf/hgp8QsiVw5rBr6pPADhXgi+EkBLZyIefu0XkqIg8ICJ261VCyBVJ0eD/MoAbARwEMAfg89YTReSQiBwRkSPN8/Z3REJIuRQKflU9pao9Vc0BfAXALc5zD6vqrKrO1rfZvyEnhJRLoeAXkb2r/vwggOdG4w4hpCyGkfq+AeDdAHaKyAkAnwHwbhE5iH7FsOMAPjHMwXqaYKETru3W7nntjAwZsKgW0rHlPLddl7XdqqcGP/OwZytsyJ0z48mY5lQZtf0AoNWyD7ZknC8AaDtO1rLwHNeNGo4AkGV2KmNesaVgrxaiWppewXp7bg0/JxtQnGxAs5VX0ZZiQ7Jm8KvqHYHN92+CL4SQErmCfupACCkTBj8hkcLgJyRSGPyERAqDn5BIKbWAp4iaWV1eu660Gh7jZXrlRuFGAEDFGZg5tlpYm+tO2GM6k/b7a2fa9rFj181Er+bIXoZ8qKkjQ21C+piV1TddaZljalVbgl125Dwvq89sl7YZL/oqg3d+QiKFwU9IpDD4CYkUBj8hkcLgJyRSGPyEREqpUl8CxWQazpqbrjoSUD08pl236wN06478U7fT6dLpSXvclong9uYOW4dq7rD9aO605bduw8kCq3o97cI2adhSaqXi2BwJdjqzi7NszZaD21cq9lxN1+1rYKFuZ072anZGqCUDusVTI4F3fkIihcFPSKQw+AmJFAY/IZHC4CckUkpd7a8mXVzbCPf/yBJ7VfmNyfAq+9yUnf3SmbZXgLvb7Lp03tthZ2tYXVjZZQ9a2ufU97vGXt2uOEkuHnkeXsXOMtuP6Ya9ar9v4rxp21u1bddkF0ybxUwjrBAAwGuT9vXRnXDOdcNY1fdue137WC5pwXtpbpwba/uI4J2fkEhh8BMSKQx+QiKFwU9IpDD4CYkUBj8hkTJMu64DAL4G4BoAOYDDqvolEZkB8E0A16Hfsusjqjrv7asiPVMeyp3eW3ONrcHtJ51klW7DkX8caQiwZcDmjvB0NXfYe/PkvBv2njVtk5ndNqzr9ABb6oSTlhKrjxeAHfUl03agbp/SG6qnTdvudCG43artBwAvNHabtl/W95q2Xt2paWjVcmRiz1B3/i6AT6vqWwC8E8AnReRmAPcAeFxVbwLw+OBvQshVwprBr6pzqvrU4PECgGMA9gG4HcCDg6c9COADm+UkIWT0rOs7v4hcB+DtAJ4EsEdV54D+GwQA+zMbIeSKY+jgF5EpAN8B8ClVvbiOcYdE5IiIHFmct9szE0LKZajgF5EK+oH/dVX97mDzKRHZO7DvBRBc/VHVw6o6q6qzU9udzguEkFJZM/hFRADcD+CYqn5hlekRAHcOHt8J4Pujd48QslkMk9V3K4CPAXhWRJ4ebLsXwGcBPCwidwF4BcCH1zyY5NiRLgZtnYotv+2qhcekDTvzLa/Ydfq6dfs9TxNbAmpPh8e1Zuzsq7077ey2g9tP2OOq9riO2nM11w7Lois9+1PXVGrLkfur4SxMALg2s2XAnen6v+JdU7O/TVZr9v46FbuWY14kb9W5BpDbsuLVxppTo6o/BkwR/r2jdYcQUhb8hR8hkcLgJyRSGPyERAqDn5BIYfATEiklt+vKMZmEZaXpZMUc1zBkIy9TTR21xhnm0jPUQ520JccD03aRyz+Yesm0XZvZEtuS2jLmi9me4PYLvYY5xsu0u65iZx7uz+zXvTMNF1dNEZZtAWB3xZb6Jo2WbQBwrjbirD5PztNiNk9CHhe88xMSKQx+QiKFwU9IpDD4CYkUBj8hkcLgJyRSSpX6Oprhtc72oO1/W7vMcS8s7Azvb9nOVKs4bc5yr36npxFadO330PlmuM8gAJzpbjFtv1M9Zdq2ws7Ca1bCczKZTJpjKmJLdjOp3T/PYzEP9/875WQXnu7Y89Hs2Jeqo1Tasm7RPnieROjYxJEPTRkwsy9U6Rkveh2XL+/8hEQKg5+QSGHwExIpDH5CIoXBT0iklLraf64zgW/N/X7Q9vIbM+a4zivhlerGOfu9qxruFgXAr+GX9OxVWavU3cTL9jQ+39pv2v7xfLjeHgDM32Svzr9r6lemrS7hJKh9Tr29ROyV76ZTL/BIy/b/V61we62fnL/BHPPMyX2mrf2qPR+1eed8dsLnUzqOROAk4WjFUR0K1veTnjH/iXNvrhtt5WT4+znv/IRECoOfkEhh8BMSKQx+QiKFwU9IpDD4CYmUNaU+ETkA4GsArgGQAzisql8SkfsAfBzAmcFT71XVR719tToZnn/N6OR91pAuAEy+Fn6Pqiza0kpmlwRE1rLHWdIQAKTGOHUkmaRj21Y606btBxO/a9pe32lLbFkSlrAmErsGXi2xE3uWc7te4FzTTsR58UI4GWvu9XBiFwCkr9vHmjxty2/VC/Y5a7wRng/pFkzs8diMZKFNZBidvwvg06r6lIhMA/i5iDw2sH1RVf9h89wjhGwWw/TqmwMwN3i8ICLHANi/xiCEXBWs6zu/iFwH4O0AnhxsultEjorIAyJif54jhFxxDB38IjIF4DsAPqWqFwF8GcCNAA6i/8ng88a4QyJyRESO9C4ujcBlQsgoGCr4RaSCfuB/XVW/CwCqekpVe6qaA/gKgFtCY1X1sKrOqupsusX+fTYhpFzWDH4REQD3Azimql9YtX115sYHATw3evcIIZvFMKv9twL4GIBnReTpwbZ7AdwhIgcBKIDjAD6x5p46CZK5etBUPW/LHbXzYSmnsmRLPJUlW3ZJm3ZGV9qyx2ka9lFyuy5d0nPeX50MrFONsFQGAP/+hi2xSRKekyyzX3NijAGAnuN/p+VcPgvhOak4mZiNM/Y1MHHKPi+187ZUWZ0Pp2LKil0H0WvXJV0nG9DKzlsLK4vQO5aF107sMoZZ7f8xwmUBXU2fEHJlw1/4ERIpDH5CIoXBT0ikMPgJiRQGPyGRUmoBz7QNTL0SljW8DL36+bDkkTjZeZkn563Y0pBb2NGqs9ixJZ5sxZEBO17fMNvWmQ7LpR6OGome14HK2WfVThREthQe6WXg1eeLyXmVi+GipQCQLhlOehl4RW1ewU2PIpLeCOCdn5BIYfATEikMfkIihcFPSKQw+AmJFAY/IZFSqtSXdICJU2FZI207GXoLhtTnSGxegcakWVTqW3/WlqOwQZ23XiuDEAA6i844qxikc6zcUxwdElthM89n1ZF03UxMJ9tSnEw2zcIvXDxZzslydHF6/HmZgqZEWGR/66gFyjs/IZHC4CckUhj8hEQKg5+QSGHwExIpDH5CIqVUqU96iupCWLJJ2p7MY/Rb8womOtKKJ6Mht21S5L3SkaE8+cqVvdq2jypWP0FziD8fjkLlSWxiKKZeL0Rvf3lm+5hP2YJqlhpSX9PWKT21TI39rYV4Up91LE/qMw80/Bje+QmJFAY/IZHC4CckUhj8hEQKg5+QSFlztV9E6gCeAFAbPP/bqvoZEbkewEMAZgA8BeBjqupUdQOgdsKNt9Jr7s5Z2XQ6YblL3+pk4qiRAKMVb3+OzVll92rWeSvw1kvzjlVoVbkghhjRt3ltsrzLw50P47VldjaTeyU64zzcfRa49k1GvNrfAvAeVX0b+u24bxORdwL4HIAvqupNAOYB3FXAVULImFgz+LXPpSTSyuCfAngPgG8Ptj8I4AOb4iEhZFMY6ju/iKSDDr2nATwG4EUA51X10mfTEwD2bY6LhJDNYKjgV9Weqh4EsB/ALQDeEnpaaKyIHBKRIyJypNNZKu4pIWSkrGu1X1XPA/gvAO8EsE1ELi0Y7gdw0hhzWFVnVXW2UpnciK+EkBGyZvCLyC4R2TZ43ADwJwCOAfgRgA8NnnYngO9vlpOEkNEzTGLPXgAPikiK/pvFw6r6byLySwAPicjfAfhvAPdvmpeGFFJEHlzzUF7ihin12fJPbtSQA3yJLVuypb6kvf72Turl7jiv2aqBVxQ3iajoPgtIlXnVvvTF87FoS66yWIfUt2bwq+pRAG8PbH8J/e//hJCrkCv8bYwQslkw+AmJFAY/IZHC4CckUhj8hESK6CbIZebBRM4AeHnw504AZ0s7uA39eDP0481cbX78tqruGmaHpQb/mw4sckRVZ8dycPpBP+gHP/YTEisMfkIiZZzBf3iMx14N/Xgz9OPN/Mb6Mbbv/ISQ8cKP/YREyliCX0RuE5H/EZEXROSecfgw8OO4iDwrIk+LyJESj/uAiJwWkedWbZsRkcdE5PnB/9vH5Md9IvLaYE6eFpH3leDHARH5kYgcE5FfiMhfDraXOieOH6XOiYjUReSnIvLMwI+/HWy/XkSeHMzHN0WkuqEDqWqp/9BPjH0RwA0AqgCeAXBz2X4MfDkOYOcYjvsuAO8A8NyqbX8P4J7B43sAfG5MftwH4K9Kno+9AN4xeDwN4NcAbi57Thw/Sp0T9NsFTg0eVwA8iX4BnYcBfHSw/Z8A/MVGjjOOO/8tAF5Q1Ze0X+r7IQC3j8GPsaGqTwA4d9nm29EvhAqUVBDV8KN0VHVOVZ8aPF5Av1jMPpQ8J44fpaJ9Nr1o7jiCfx+AV1f9Pc7inwrghyLycxE5NCYfLrFHVeeA/kUIYPcYfblbRI4OvhZs+teP1YjIdejXj3gSY5yTy/wASp6TMormjiP4Q6VGxiU53Kqq7wDw5wA+KSLvGpMfVxJfBnAj+j0a5gB8vqwDi8gUgO8A+JSqXizruEP4Ufqc6AaK5g7LOIL/BIADq/42i39uNqp6cvD/aQDfw3grE50Skb0AMPj/9DicUNVTgwsvB/AVlDQnIlJBP+C+rqrfHWwufU5CfoxrTgbHXnfR3GEZR/D/DMBNg5XLKoCPAnikbCdEZFJEpi89BvBnAJ7zR20qj6BfCBUYY0HUS8E24IMoYU5ERNCvAXlMVb+wylTqnFh+lD0npRXNLWsF87LVzPehv5L6IoC/HpMPN6CvNDwD4Bdl+gHgG+h/fOyg/0noLgA7ADwO4PnB/zNj8uNfADwL4Cj6wbe3BD/+CP2PsEcBPD34976y58Txo9Q5AfB76BfFPYr+G83frLpmfwrgBQDfAlDbyHH4Cz9CIoW/8CMkUhj8hEQKg5+QSGHwExIpDH5CIoXBT0ikMPgJiRQGPyGR8n+wRbNU06Xx1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1, len(X_train))\n",
    "print(\"Label %d is\" % i, y_train[i])\n",
    "plt.imshow(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c03b32fdd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c03b37add8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 1)) #width 10, height 1\n",
    "\n",
    "plt.subplot(1, 10, 1)\n",
    "plt.imshow(X_train[0], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "print('label for each of the below image: %s' % (np.argmax(y_train[0:10][1])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the image data from 3D to 2D by using reshape and flatten methods from numpy\n",
    "X_train_reshaped = np.array([X_train[i].flatten() for i in range(0,X_train.shape[0])])\n",
    "print(X_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_test_reshaped = np.array([X_test[i].flatten() for i in range(0,X_test.shape[0])])\n",
    "print(X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5235555555555556"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy :  0.5235555555555556\n",
      "Confusion Metrics :  [[1233   95  100  136  117  163  318   98  249  335]\n",
      " [  68 1335  215  251  247  164  122  227  115  137]\n",
      " [  39   70  992  136   41   62   38  116   62   70]\n",
      " [  39   83  107  734   60  268   72   84  119   92]\n",
      " [  51   75   55   50 1182   63  129   26  100   65]\n",
      " [  46   34   30  160   14  683  128   35  120  108]\n",
      " [ 113   32   37   42   54  156  741   35  253   56]\n",
      " [  37   51  138   54   17   31   23 1116   28   69]\n",
      " [  86   21   54   98   34  114  210   30  655  119]\n",
      " [ 102   32   75   58   46   64   51   41  111  753]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model with KNN Classifier\n",
    "kNN_model = KNeighborsClassifier(n_neighbors = 15)\n",
    "kNN_model.fit(X_train_reshaped,y_train)\n",
    "\n",
    "kNN_model.score(X_test_reshaped, y_test)\n",
    "\n",
    "y_predict = kNN_model.predict(X_test_reshaped)\n",
    "\n",
    "print(\"KNN Model Accuracy : \", metrics.accuracy_score(y_predict, y_test))\n",
    "      \n",
    "print(\"Confusion Metrics : \", metrics.confusion_matrix(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the classification metric report (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification report :    \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      1814\n",
      "          1       0.86      0.84      0.85      1828\n",
      "          2       0.87      0.84      0.85      1803\n",
      "          3       0.79      0.77      0.78      1719\n",
      "          4       0.85      0.88      0.86      1812\n",
      "          5       0.78      0.86      0.82      1768\n",
      "          6       0.84      0.82      0.83      1832\n",
      "          7       0.88      0.88      0.88      1808\n",
      "          8       0.83      0.78      0.80      1812\n",
      "          9       0.81      0.82      0.81      1804\n",
      "\n",
      "avg / total       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_cr=metrics.classification_report(y_test, y_predict)\n",
    "print(\"KNN Classification report :    \\n\", knn_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement batch normalization for training the neural network (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varuraje.ORADEV\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32)))\n",
    "\n",
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape\n",
    "X_val.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 6s 142us/sample - loss: 2.0355 - acc: 0.3057 - val_loss: 1.6811 - val_acc: 0.4820\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 1.4691 - acc: 0.5575 - val_loss: 1.2697 - val_acc: 0.6286\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 1.1919 - acc: 0.6456 - val_loss: 1.0849 - val_acc: 0.6859\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 1.0508 - acc: 0.6910 - val_loss: 0.9894 - val_acc: 0.7144\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.9563 - acc: 0.7174 - val_loss: 0.9161 - val_acc: 0.7313\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.8852 - acc: 0.7401 - val_loss: 0.8676 - val_acc: 0.7461\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.8264 - acc: 0.7561 - val_loss: 0.8254 - val_acc: 0.7603\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 0.7780 - acc: 0.7698 - val_loss: 0.7884 - val_acc: 0.7729\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.7365 - acc: 0.7821 - val_loss: 0.7607 - val_acc: 0.7817\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.7015 - acc: 0.7922 - val_loss: 0.7437 - val_acc: 0.7854\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.6714 - acc: 0.8021 - val_loss: 0.7269 - val_acc: 0.7908\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.6444 - acc: 0.8078 - val_loss: 0.6934 - val_acc: 0.8038\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 0.6215 - acc: 0.8161 - val_loss: 0.6806 - val_acc: 0.8084\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.6003 - acc: 0.8202 - val_loss: 0.6738 - val_acc: 0.8078\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 0.5798 - acc: 0.8275 - val_loss: 0.6635 - val_acc: 0.8111\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 4s 92us/sample - loss: 0.5642 - acc: 0.8323 - val_loss: 0.6657 - val_acc: 0.8079\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.5476 - acc: 0.8381 - val_loss: 0.6662 - val_acc: 0.8108\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 4s 93us/sample - loss: 0.5338 - acc: 0.8422 - val_loss: 0.6334 - val_acc: 0.8224\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.5198 - acc: 0.8459 - val_loss: 0.6320 - val_acc: 0.8215\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.5072 - acc: 0.8501 - val_loss: 0.6234 - val_acc: 0.8256\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.4945 - acc: 0.8534 - val_loss: 0.6309 - val_acc: 0.8234\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.4842 - acc: 0.8570 - val_loss: 0.6101 - val_acc: 0.8308\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 4s 105us/sample - loss: 0.4748 - acc: 0.8600 - val_loss: 0.6252 - val_acc: 0.8254\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.4634 - acc: 0.8622 - val_loss: 0.5979 - val_acc: 0.8342\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.4550 - acc: 0.8639 - val_loss: 0.6118 - val_acc: 0.8281\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.4463 - acc: 0.8674 - val_loss: 0.6167 - val_acc: 0.8277\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.4364 - acc: 0.8701 - val_loss: 0.6021 - val_acc: 0.8326\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 4s 94us/sample - loss: 0.4287 - acc: 0.8723 - val_loss: 0.6045 - val_acc: 0.8331\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.4206 - acc: 0.8744 - val_loss: 0.6009 - val_acc: 0.8342\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 4s 95us/sample - loss: 0.4145 - acc: 0.8767 - val_loss: 0.6034 - val_acc: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c06e1e46a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train, trainY, validation_data=(np.array(X_test), testY), epochs=30, batch_size=100, validation_split=0.01, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 72us/sample - loss: 0.6034 - acc: 0.8373\n",
      "[0.603364553451538, 0.83727777]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, testY)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Networks Classification report :    \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      1814\n",
      "          1       0.86      0.84      0.85      1828\n",
      "          2       0.87      0.84      0.85      1803\n",
      "          3       0.79      0.77      0.78      1719\n",
      "          4       0.85      0.88      0.86      1812\n",
      "          5       0.78      0.86      0.82      1768\n",
      "          6       0.84      0.82      0.83      1832\n",
      "          7       0.88      0.88      0.88      1808\n",
      "          8       0.83      0.78      0.80      1812\n",
      "          9       0.81      0.82      0.81      1804\n",
      "\n",
      "avg / total       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_cr=metrics.classification_report(y_test, y_predict)\n",
    "print(\"Neural Networks Classification report :    \\n\", nn_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The F1-Score from KNN Classifier and Neural Network is 0.53 and 0.87 respectively. The KNN is finding the accuracy of the provided features using the distance formula, so the accuracy is less in figures.Meantime, the Neural Network is processing the provided features by adjesting weights on the Dence layers and finding more classifications. This is clearly evident from the F1-score of the NN classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
