{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics\n",
    "# Create KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "X_train\n",
      "X_val\n",
      "y_test\n",
      "y_train\n",
      "y_val\n"
     ]
    }
   ],
   "source": [
    "# Read H5 file\n",
    "f = h5.File(\"SVHN_single_grey1.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = [n for n in f.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['X_test'].shape\n",
    "f['X_train'].shape\n",
    "f['X_val'].shape\n",
    "f['y_test'].shape\n",
    "f['y_train'].shape\n",
    "f['y_val'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetching and understand the train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = f['X_test']\n",
    "X_train = f['X_train']\n",
    "X_val = f['X_val']\n",
    "\n",
    "y_test = f['y_test']\n",
    "y_train = f['y_train']\n",
    "y_val = f['y_val']\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape\n",
    "X_val.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 4648 is 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ca8e9dfeb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1, len(X_train))\n",
    "print(\"Label %d is\" % i, y_train[i])\n",
    "plt.imshow(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ca8ea32eb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ca8fa51be0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 1)) #width 10, height 1\n",
    "\n",
    "plt.subplot(1, 10, 1)\n",
    "plt.imshow(X_train[0], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "print('label for each of the below image: %s' % (np.argmax(y_train[0:10][1])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the image data from 3D to 2D by using reshape and flatten methods from numpy\n",
    "X_train_reshaped = np.array([X_train[i].flatten() for i in range(0,X_train.shape[0])])\n",
    "print(X_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_test_reshaped = np.array([X_test[i].flatten() for i in range(0,X_test.shape[0])])\n",
    "print(X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5235555555555556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy :  0.5235555555555556\n",
      "Confusion Metrics : \n",
      " [[1233   95  100  136  117  163  318   98  249  335]\n",
      " [  68 1335  215  251  247  164  122  227  115  137]\n",
      " [  39   70  992  136   41   62   38  116   62   70]\n",
      " [  39   83  107  734   60  268   72   84  119   92]\n",
      " [  51   75   55   50 1182   63  129   26  100   65]\n",
      " [  46   34   30  160   14  683  128   35  120  108]\n",
      " [ 113   32   37   42   54  156  741   35  253   56]\n",
      " [  37   51  138   54   17   31   23 1116   28   69]\n",
      " [  86   21   54   98   34  114  210   30  655  119]\n",
      " [ 102   32   75   58   46   64   51   41  111  753]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model with KNN Classifier\n",
    "kNN_model = KNeighborsClassifier(n_neighbors = 15)\n",
    "kNN_model.fit(X_train_reshaped,y_train)\n",
    "\n",
    "kNN_model.score(X_test_reshaped, y_test)\n",
    "\n",
    "y_predict = kNN_model.predict(X_test_reshaped)\n",
    "\n",
    "print(\"KNN Model Accuracy : \", metrics.accuracy_score(y_predict, y_test))\n",
    "      \n",
    "print(\"Confusion Metrics : \\n\", metrics.confusion_matrix(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the classification metric report (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification report :    \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.68      0.53      1814\n",
      "          1       0.46      0.73      0.57      1828\n",
      "          2       0.61      0.55      0.58      1803\n",
      "          3       0.44      0.43      0.43      1719\n",
      "          4       0.66      0.65      0.66      1812\n",
      "          5       0.50      0.39      0.44      1768\n",
      "          6       0.49      0.40      0.44      1832\n",
      "          7       0.71      0.62      0.66      1808\n",
      "          8       0.46      0.36      0.41      1812\n",
      "          9       0.56      0.42      0.48      1804\n",
      "\n",
      "avg / total       0.53      0.52      0.52     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_cr=metrics.classification_report(y_test, y_predict)\n",
    "print(\"KNN Classification report :    \\n\", knn_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement batch normalization for training the neural network (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varuraje.ORADEV\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape\n",
    "X_val.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\varuraje.ORADEV\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 2.1023 - acc: 0.2733 - val_loss: 1.7634 - val_acc: 0.4644\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 5s 115us/sample - loss: 1.5181 - acc: 0.5456 - val_loss: 1.3009 - val_acc: 0.6241\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 1.2081 - acc: 0.6435 - val_loss: 1.1004 - val_acc: 0.6810\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 1.0581 - acc: 0.6855 - val_loss: 0.9936 - val_acc: 0.7092\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.9618 - acc: 0.7131 - val_loss: 0.9253 - val_acc: 0.7288\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.8881 - acc: 0.7350 - val_loss: 0.8671 - val_acc: 0.7482\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.8295 - acc: 0.7538 - val_loss: 0.8362 - val_acc: 0.7550\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.7815 - acc: 0.7693 - val_loss: 0.8041 - val_acc: 0.7653\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 4s 104us/sample - loss: 0.7425 - acc: 0.7806 - val_loss: 0.7573 - val_acc: 0.7809\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.7088 - acc: 0.7879 - val_loss: 0.7414 - val_acc: 0.7828\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.6789 - acc: 0.7983 - val_loss: 0.7311 - val_acc: 0.7887\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 4s 99us/sample - loss: 0.6529 - acc: 0.8060 - val_loss: 0.7091 - val_acc: 0.7974\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.6301 - acc: 0.8123 - val_loss: 0.6915 - val_acc: 0.8023\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 4s 104us/sample - loss: 0.6095 - acc: 0.8196 - val_loss: 0.6731 - val_acc: 0.8079\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 4s 104us/sample - loss: 0.5884 - acc: 0.8251 - val_loss: 0.6713 - val_acc: 0.8076\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 5s 109us/sample - loss: 0.5723 - acc: 0.8301 - val_loss: 0.6551 - val_acc: 0.8141\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.5569 - acc: 0.8347 - val_loss: 0.6486 - val_acc: 0.8172\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.5387 - acc: 0.8410 - val_loss: 0.6475 - val_acc: 0.8181\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.5265 - acc: 0.8425 - val_loss: 0.6366 - val_acc: 0.8206\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 4s 96us/sample - loss: 0.5151 - acc: 0.8463 - val_loss: 0.6204 - val_acc: 0.8288\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 4s 101us/sample - loss: 0.5014 - acc: 0.8505 - val_loss: 0.6507 - val_acc: 0.8195\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 5s 111us/sample - loss: 0.4904 - acc: 0.8556 - val_loss: 0.6212 - val_acc: 0.8272\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 0.4795 - acc: 0.8565 - val_loss: 0.6075 - val_acc: 0.8299\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 4s 97us/sample - loss: 0.4689 - acc: 0.8606 - val_loss: 0.6080 - val_acc: 0.8319\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.4596 - acc: 0.8637 - val_loss: 0.6122 - val_acc: 0.8296\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.4507 - acc: 0.8654 - val_loss: 0.6053 - val_acc: 0.8308\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 0.4420 - acc: 0.8676 - val_loss: 0.6139 - val_acc: 0.8291\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.4335 - acc: 0.8712 - val_loss: 0.5986 - val_acc: 0.8331\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.4262 - acc: 0.8729 - val_loss: 0.6117 - val_acc: 0.8302\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 4s 98us/sample - loss: 0.4169 - acc: 0.8758 - val_loss: 0.6035 - val_acc: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cac20f7780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train, trainY, validation_data=(np.array(X_test), testY), epochs=30, batch_size=100, validation_split=0.01, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 76us/sample - loss: 0.6035 - acc: 0.8327\n",
      "[0.6035474868218104, 0.83272225]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, testY)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Networks Classification report :    \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.89      0.85      1814\n",
      "          1       0.80      0.87      0.84      1828\n",
      "          2       0.89      0.84      0.86      1803\n",
      "          3       0.77      0.78      0.78      1719\n",
      "          4       0.88      0.86      0.87      1812\n",
      "          5       0.81      0.84      0.82      1768\n",
      "          6       0.84      0.82      0.83      1832\n",
      "          7       0.87      0.87      0.87      1808\n",
      "          8       0.85      0.76      0.80      1812\n",
      "          9       0.82      0.81      0.81      1804\n",
      "\n",
      "avg / total       0.83      0.83      0.83     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_cr=metrics.classification_report(y_test, y_predict)\n",
    "print(\"Neural Networks Classification report :    \\n\", nn_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The F1-Score from KNN Classifier and Neural Network is 0.52 and 0.83 respectively. The KNN is finding the accuracy of the provided features using the distance formula, so the accuracy is less in figures.Meantime, the Neural Network is processing the provided features by adjesting weights on the Dence layers and finding more classifications. This is clearly evident from the F1-score of the NN classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
